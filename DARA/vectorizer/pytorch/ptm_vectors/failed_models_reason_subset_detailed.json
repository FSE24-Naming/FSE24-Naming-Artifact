{"SZTAKI-HLT/mT5-small-HunSum-1": ["ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds"], "eslamxm/mt5-base-arabic": ["ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds"], "Ayham/xlmroberta_gpt2_summarization_xsum": ["ValueError: Unrecognized configuration class <class 'transformers.models.encoder_decoder.configuration_encoder_decoder.EncoderDecoderConfig'> for this kind of AutoModel: AutoModel."], "chrisjay/afrospeech-wav2vec-sna": {"AutoProcessor": ["OSError: Can't load tokenizer for 'chrisjay/afrospeech-wav2vec-sna'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'chrisjay/afrospeech-wav2vec-sna' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.", "OSError: Can't load tokenizer for 'chrisjay/afrospeech-wav2vec-sna'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'chrisjay/afrospeech-wav2vec-sna' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer."], "AutoTokenizer": ["OSError: Can't load tokenizer for 'chrisjay/afrospeech-wav2vec-sna'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'chrisjay/afrospeech-wav2vec-sna' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer."], "AutoImageProcessor": ["AttributeError: 'NoneType' object has no attribute 'from_dict'"], "AutoFeatureExtractor": ["TypeError: __call__() missing 1 required positional argument: 'raw_speech'"]}, "lmqg/mt5-small-dequad-qg-ae": ["ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds"], "doc2query/msmarco-vietnamese-mt5-base-v1": ["ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds"], "enelpol/czywiesz-context": {"AutoProcessor": ["ValueError: Unrecognized processing class in enelpol/czywiesz-context. Can't instantiate a processor, a tokenizer, an image processor or a feature extractor for this model. Make sure the repository containsthe files of at least one of those processing classes."], "AutoTokenizer": ["ModuleNotFoundError: No module named 'sacremoses'", "ImportError: You need to install sacremoses to use HerbertTokenizer. See https://pypi.org/project/sacremoses/ for installation."], "AutoImageProcessor": ["requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/enelpol/czywiesz-context/resolve/main/preprocessor_config.json", "huggingface_hub.utils._errors.EntryNotFoundError: 404 Client Error. (Request ID: Root=1-64b1f093-1e1154955f4c8d4e74147c4d)", "OSError: enelpol/czywiesz-context does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co/enelpol/czywiesz-context/main' for available files."], "AutoFeatureExtractor": ["requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/enelpol/czywiesz-context/resolve/main/preprocessor_config.json", "huggingface_hub.utils._errors.EntryNotFoundError: 404 Client Error. (Request ID: Root=1-64b1f093-5c8bbc0833e9a69679f14db3)", "OSError: enelpol/czywiesz-context does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co/enelpol/czywiesz-context/main' for available files."]}, "vasista22/wav2vec2-360h-base-ft-100h": ["RuntimeError: Input type (torch.cuda.LongTensor) and weight type (torch.cuda.FloatTensor) should be the same"], "Helsinki-NLP/opus-mt-tc-big-en-zle": ["ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds"], "asapp/sew-d-base-plus-400k": {"AutoProcessor": ["OSError: Can't load tokenizer for 'asapp/sew-d-base-plus-400k'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'asapp/sew-d-base-plus-400k' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.", "OSError: Can't load tokenizer for 'asapp/sew-d-base-plus-400k'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'asapp/sew-d-base-plus-400k' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer."], "AutoTokenizer": ["OSError: Can't load tokenizer for 'asapp/sew-d-base-plus-400k'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'asapp/sew-d-base-plus-400k' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer."], "AutoImageProcessor": ["AttributeError: 'NoneType' object has no attribute 'from_dict'"], "AutoFeatureExtractor": ["TypeError: __call__() missing 1 required positional argument: 'raw_speech'"]}, "lmqg/mt5-small-jaquad-ae": ["ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds"], "Blaise-g/longt5_tglobal_large_scitldr": ["ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds"], "speechbrain/asr-wav2vec2-commonvoice-rw": ["OSError: speechbrain/asr-wav2vec2-commonvoice-rw does not appear to have a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack."], "Edresson/wav2vec2-large-100k-voxpopuli-ft-TTS-Dataset-portuguese": ["RuntimeError: Input type (torch.cuda.LongTensor) and weight type (torch.cuda.FloatTensor) should be the same"], "infinitejoy/wav2vec2-large-xls-r-300m-basaa": ["RuntimeError: Input type (torch.cuda.LongTensor) and weight type (torch.cuda.FloatTensor) should be the same"], "danicodes/autonlp-legal-text-summary-457311749": ["ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds"], "Gabriel/bart-base-cnn-swe": ["TypeError: forward() got an unexpected keyword argument 'token_type_ids'"], "microsoft/tapex-large-finetuned-wtq": {"AutoProcessor": ["ValueError: table input must of type `pd.DataFrame` (single example), `List[pd.DataFrame]` (batch of examples). "], "AutoTokenizer": ["AttributeError: 'str' object has no attribute 'empty'"], "AutoImageProcessor": ["requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/microsoft/tapex-large-finetuned-wtq/resolve/main/preprocessor_config.json", "huggingface_hub.utils._errors.EntryNotFoundError: 404 Client Error. (Request ID: Root=1-64b1f0dc-0df622a51ddaa66d6e5c29e2)", "OSError: microsoft/tapex-large-finetuned-wtq does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co/microsoft/tapex-large-finetuned-wtq/main' for available files."], "AutoFeatureExtractor": ["requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/microsoft/tapex-large-finetuned-wtq/resolve/main/preprocessor_config.json", "huggingface_hub.utils._errors.EntryNotFoundError: 404 Client Error. (Request ID: Root=1-64b1f0dc-40d570bb231a38837e0dc2d6)", "OSError: microsoft/tapex-large-finetuned-wtq does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co/microsoft/tapex-large-finetuned-wtq/main' for available files."]}, "Helsinki-NLP/opus-mt-tc-big-en-lv": ["ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds"], "alefiury/wav2vec2-large-xlsr-53-coraa-brazilian-portuguese-gain-normalization-sna": ["RuntimeError: Input type (torch.cuda.LongTensor) and weight type (torch.cuda.FloatTensor) should be the same"], "m3hrdadfi/wav2vec2-large-xlsr-persian-shemo": ["RuntimeError: Input type (torch.cuda.LongTensor) and weight type (torch.cuda.FloatTensor) should be the same"], "nickmuchi/wav2vec2-base-finetuned-spgispeech-dev": ["RuntimeError: Input type (torch.cuda.LongTensor) and weight type (torch.cuda.FloatTensor) should be the same"], "doc2query/msmarco-japanese-mt5-base-v1": ["ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds"], "eslamxm/mbert2mbert-finetuned-ar-xlsum": ["ValueError: Unrecognized configuration class <class 'transformers.models.encoder_decoder.configuration_encoder_decoder.EncoderDecoderConfig'> for this kind of AutoModel: AutoModel."], "it5/mt5-base-informal-to-formal": ["ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds"], "infinitejoy/wav2vec2-large-xls-r-300m-bulgarian": ["RuntimeError: Input type (torch.cuda.LongTensor) and weight type (torch.cuda.FloatTensor) should be the same"], "microsoft/tapex-base-finetuned-wikisql": {"AutoProcessor": ["ValueError: table input must of type `pd.DataFrame` (single example), `List[pd.DataFrame]` (batch of examples). "], "AutoTokenizer": ["AttributeError: 'str' object has no attribute 'empty'"], "AutoImageProcessor": ["requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/microsoft/tapex-base-finetuned-wikisql/resolve/main/preprocessor_config.json", "huggingface_hub.utils._errors.EntryNotFoundError: 404 Client Error. (Request ID: Root=1-64b1f116-1c4dbb875eda97ab55913e0e)", "OSError: microsoft/tapex-base-finetuned-wikisql does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co/microsoft/tapex-base-finetuned-wikisql/main' for available files."], "AutoFeatureExtractor": ["requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/microsoft/tapex-base-finetuned-wikisql/resolve/main/preprocessor_config.json", "huggingface_hub.utils._errors.EntryNotFoundError: 404 Client Error. (Request ID: Root=1-64b1f116-7bb2501b7ae036452e822e35)", "OSError: microsoft/tapex-base-finetuned-wikisql does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co/microsoft/tapex-base-finetuned-wikisql/main' for available files."]}, "ydshieh/dummy_debug": {"AutoProcessor": ["requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/ydshieh/dummy_debug/resolve/main/preprocessor_config.json", "huggingface_hub.utils._errors.EntryNotFoundError: 404 Client Error. (Request ID: Root=1-64b1f118-6ec28413719863504e3693bd)", "OSError: ydshieh/dummy_debug does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co/ydshieh/dummy_debug/main' for available files."], "AutoTokenizer": ["KeyError: <class 'transformers.models.vision_text_dual_encoder.configuration_vision_text_dual_encoder.VisionTextDualEncoderConfig'>"], "AutoImageProcessor": ["requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/ydshieh/dummy_debug/resolve/main/preprocessor_config.json", "huggingface_hub.utils._errors.EntryNotFoundError: 404 Client Error. (Request ID: Root=1-64b1f118-711f5a602d1d77ab4fa30a82)", "OSError: ydshieh/dummy_debug does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co/ydshieh/dummy_debug/main' for available files."], "AutoFeatureExtractor": ["requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/ydshieh/dummy_debug/resolve/main/preprocessor_config.json", "huggingface_hub.utils._errors.EntryNotFoundError: 404 Client Error. (Request ID: Root=1-64b1f118-38ce37a873a70a151a980784)", "OSError: ydshieh/dummy_debug does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co/ydshieh/dummy_debug/main' for available files."]}, "robingeibel/bigbird-large-finetuned-big_patent": {"AutoProcessor": ["ValueError: Unrecognized processing class in robingeibel/bigbird-large-finetuned-big_patent. Can't instantiate a processor, a tokenizer, an image processor or a feature extractor for this model. Make sure the repository containsthe files of at least one of those processing classes."], "AutoTokenizer": ["OSError: Can't load tokenizer for 'robingeibel/bigbird-large-finetuned-big_patent'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'robingeibel/bigbird-large-finetuned-big_patent' is the correct path to a directory containing all relevant files for a BigBirdTokenizerFast tokenizer."], "AutoImageProcessor": ["requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/robingeibel/bigbird-large-finetuned-big_patent/resolve/main/preprocessor_config.json", "huggingface_hub.utils._errors.EntryNotFoundError: 404 Client Error. (Request ID: Root=1-64b1f133-2b601b7b6fec1b0840665382)", "OSError: robingeibel/bigbird-large-finetuned-big_patent does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co/robingeibel/bigbird-large-finetuned-big_patent/main' for available files."], "AutoFeatureExtractor": ["requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/robingeibel/bigbird-large-finetuned-big_patent/resolve/main/preprocessor_config.json", "huggingface_hub.utils._errors.EntryNotFoundError: 404 Client Error. (Request ID: Root=1-64b1f133-4e991bbc216968b55172b438)", "OSError: robingeibel/bigbird-large-finetuned-big_patent does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co/robingeibel/bigbird-large-finetuned-big_patent/main' for available files."]}, "ConvLab/mt5-small-nlg-all-crosswoz": ["ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds"], "Tritkoman/English2AlgerianArabic": ["ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds"], "nielsr/layoutxlm-finetuned-xfund-fr": ["ImportError: "], "rootacess/marian-finetuned-kde4-en-to-fr": ["ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds"], "patrickvonplaten/wav2vec2-base-100h-2nd-try": {"AutoProcessor": ["OSError: Can't load tokenizer for 'patrickvonplaten/wav2vec2-base-100h-2nd-try'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'patrickvonplaten/wav2vec2-base-100h-2nd-try' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.", "OSError: Can't load tokenizer for 'patrickvonplaten/wav2vec2-base-100h-2nd-try'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'patrickvonplaten/wav2vec2-base-100h-2nd-try' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer."], "AutoTokenizer": ["OSError: Can't load tokenizer for 'patrickvonplaten/wav2vec2-base-100h-2nd-try'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'patrickvonplaten/wav2vec2-base-100h-2nd-try' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer."], "AutoImageProcessor": ["ValueError: Unrecognized image processor in patrickvonplaten/wav2vec2-base-100h-2nd-try. Should have a `image_processor_type` key in its preprocessor_config.json of config.json, or one of the following `model_type` keys in its config.json: align, beit, bit, blip, blip-2, bridgetower, chinese_clip, clip, clipseg, conditional_detr, convnext, convnextv2, cvt, data2vec-vision, deformable_detr, deit, deta, detr, dinat, donut-swin, dpt, efficientformer, efficientnet, flava, focalnet, git, glpn, groupvit, imagegpt, layoutlmv2, layoutlmv3, levit, mask2former, maskformer, mgp-str, mobilenet_v1, mobilenet_v2, mobilevit, nat, oneformer, owlvit, perceiver, pix2struct, poolformer, regnet, resnet, sam, segformer, swin, swin2sr, swinv2, table-transformer, timesformer, tvlt, upernet, van, videomae, vilt, vit, vit_hybrid, vit_mae, vit_msn, xclip, yolos"], "AutoFeatureExtractor": ["TypeError: __call__() missing 1 required positional argument: 'raw_speech'"]}, "facebook/wav2vec2-xls-r-1b-21-to-en": ["ValueError: Unrecognized configuration class <class 'transformers.models.speech_encoder_decoder.configuration_speech_encoder_decoder.SpeechEncoderDecoderConfig'> for this kind of AutoModel: AutoModel."], "Intel/bert-base-uncased-mrpc-int8-dynamic": ["ModuleNotFoundError: No module named 'neural_compressor'", "UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 64: invalid start byte", "OSError: Unable to load weights from pytorch checkpoint file for 'ANONYMIZED_PATH/cache_huggingface/models--Intel--bert-base-uncased-mrpc-int8-dynamic/snapshots/c2f8181123cf71cf844452d05931c41a3502d02b/pytorch_model.bin' at 'ANONYMIZED_PATH/cache_huggingface/models--Intel--bert-base-uncased-mrpc-int8-dynamic/snapshots/c2f8181123cf71cf844452d05931c41a3502d02b/pytorch_model.bin'. If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True."], "robingeibel/reformer-big_patent-wikipedia-arxiv-16384": {"AutoProcessor": ["ValueError: Unrecognized processing class in robingeibel/reformer-big_patent-wikipedia-arxiv-16384. Can't instantiate a processor, a tokenizer, an image processor or a feature extractor for this model. Make sure the repository containsthe files of at least one of those processing classes."], "AutoTokenizer": ["OSError: Can't load tokenizer for 'robingeibel/reformer-big_patent-wikipedia-arxiv-16384'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'robingeibel/reformer-big_patent-wikipedia-arxiv-16384' is the correct path to a directory containing all relevant files for a ReformerTokenizerFast tokenizer."], "AutoImageProcessor": ["requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/robingeibel/reformer-big_patent-wikipedia-arxiv-16384/resolve/main/preprocessor_config.json", "huggingface_hub.utils._errors.EntryNotFoundError: 404 Client Error. (Request ID: Root=1-64b1f158-649328ff0c967e4236ed7761)", "OSError: robingeibel/reformer-big_patent-wikipedia-arxiv-16384 does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co/robingeibel/reformer-big_patent-wikipedia-arxiv-16384/main' for available files."], "AutoFeatureExtractor": ["requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/robingeibel/reformer-big_patent-wikipedia-arxiv-16384/resolve/main/preprocessor_config.json", "huggingface_hub.utils._errors.EntryNotFoundError: 404 Client Error. (Request ID: Root=1-64b1f158-58b27761223945c37475dbd1)", "OSError: robingeibel/reformer-big_patent-wikipedia-arxiv-16384 does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co/robingeibel/reformer-big_patent-wikipedia-arxiv-16384/main' for available files."]}, "Ogayo/Hel-ach-en": {"AutoProcessor": ["ValueError: Unrecognized processing class in Ogayo/Hel-ach-en. Can't instantiate a processor, a tokenizer, an image processor or a feature extractor for this model. Make sure the repository containsthe files of at least one of those processing classes."], "AutoTokenizer": ["TypeError: expected str, bytes or os.PathLike object, not NoneType"], "AutoImageProcessor": ["requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Ogayo/Hel-ach-en/resolve/main/preprocessor_config.json", "huggingface_hub.utils._errors.EntryNotFoundError: 404 Client Error. (Request ID: Root=1-64b1f15c-24695e6d40c4b028395d5df3)", "OSError: Ogayo/Hel-ach-en does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co/Ogayo/Hel-ach-en/main' for available files."], "AutoFeatureExtractor": ["requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Ogayo/Hel-ach-en/resolve/main/preprocessor_config.json", "huggingface_hub.utils._errors.EntryNotFoundError: 404 Client Error. (Request ID: Root=1-64b1f15c-07c44bfa711c194757ea27ab)", "OSError: Ogayo/Hel-ach-en does not appear to have a file named preprocessor_config.json. Checkout 'https://huggingface.co/Ogayo/Hel-ach-en/main' for available files."]}, "sumedh/wav2vec2-large-xlsr-marathi": ["RuntimeError: Input type (torch.cuda.LongTensor) and weight type (torch.cuda.FloatTensor) should be the same"], "jonatasgrosman/exp_w2v2t_ja_hubert_s732": ["RuntimeError: Input type (torch.cuda.LongTensor) and weight type (torch.cuda.FloatTensor) should be the same"], "doc2query/msmarco-14langs-mt5-base-v1": ["ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds"], "jonatasgrosman/exp_w2v2t_ar_hubert_s290": ["RuntimeError: Input type (torch.cuda.LongTensor) and weight type (torch.cuda.FloatTensor) should be the same"], "gsarti/opus-mt-tc-base-en-nl": ["ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds"], "othrif/wav2vec2-large-xlsr-moroccan": ["RuntimeError: Input type (torch.cuda.LongTensor) and weight type (torch.cuda.FloatTensor) should be the same"], "facebook/wav2vec2-conformer-rope-large": {"AutoProcessor": ["OSError: Can't load tokenizer for 'facebook/wav2vec2-conformer-rope-large'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/wav2vec2-conformer-rope-large' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.", "OSError: Can't load tokenizer for 'facebook/wav2vec2-conformer-rope-large'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/wav2vec2-conformer-rope-large' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer."], "AutoTokenizer": ["OSError: Can't load tokenizer for 'facebook/wav2vec2-conformer-rope-large'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/wav2vec2-conformer-rope-large' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer."], "AutoImageProcessor": ["AttributeError: 'NoneType' object has no attribute 'from_dict'"], "AutoFeatureExtractor": ["TypeError: __call__() missing 1 required positional argument: 'raw_speech'"]}, "bigscience/mt0-small": ["ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds"], "jso1/wav2vec2-base-finetuned-ks": {"AutoProcessor": ["OSError: Can't load tokenizer for 'jso1/wav2vec2-base-finetuned-ks'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'jso1/wav2vec2-base-finetuned-ks' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.", "OSError: Can't load tokenizer for 'jso1/wav2vec2-base-finetuned-ks'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'jso1/wav2vec2-base-finetuned-ks' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer."], "AutoTokenizer": ["OSError: Can't load tokenizer for 'jso1/wav2vec2-base-finetuned-ks'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'jso1/wav2vec2-base-finetuned-ks' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer."], "AutoImageProcessor": ["AttributeError: 'NoneType' object has no attribute 'from_dict'"], "AutoFeatureExtractor": ["TypeError: __call__() missing 1 required positional argument: 'raw_speech'"]}, "Intel/distilbert-base-uncased-finetuned-sst-2-english-int8-static": ["ModuleNotFoundError: No module named 'neural_compressor'", "UnicodeDecodeError: 'utf-8' codec can't decode byte 0x80 in position 64: invalid start byte", "OSError: Unable to load weights from pytorch checkpoint file for 'ANONYMIZED_PATH/cache_huggingface/models--Intel--distilbert-base-uncased-finetuned-sst-2-english-int8-static/snapshots/bc1fc91ebe84493fdd44db19751fab7877779d02/pytorch_model.bin' at 'ANONYMIZED_PATH/cache_huggingface/models--Intel--distilbert-base-uncased-finetuned-sst-2-english-int8-static/snapshots/bc1fc91ebe84493fdd44db19751fab7877779d02/pytorch_model.bin'. If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True."], "reach-vb/wav2vec2-large-xls-r-1B-common_voice7-lv-ft": ["RuntimeError: Input type (torch.cuda.LongTensor) and weight type (torch.cuda.FloatTensor) should be the same"], "lmqg/mt5-small-ruquad-qag": ["ValueError: You have to specify either decoder_input_ids or decoder_inputs_embeds"]}